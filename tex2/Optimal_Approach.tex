\chapter{Optimal Approach}

In this chapter, we develop a solution method in order to solve our problem to optimality. We expect this to require a very efficient algorithm and a lot of computation power since the problem is $\mathcal{NP}$-hard. The solution method should cope with multi-leg cover constraints as defined in \Cref{ch:problem_description}. The approach is based on the underlying master theses which have already found methods to solve a simplified version of our problem. \cite{Kaiser} provide an optimal algorithm for the problem with single-leg cover constraints. This problem setting assumes that each customer has a set of alternative trips, where one of them has to be fulfilled each. We want our algorithm to produce a result in reasonable time, therefore we require already a very good solution as an initial solution. For receiving a good initial solution, we apply the Successive Heuristics as developed in \Cref{ch:heuristics}.

In order to tackle the problem, we introduce a path flow formulation which is different to the arc flow formulation of \Cref{sec:arcflow_formulation}. Since the entire solution consists of separate vehicle duties, we decompose the problems into these single duties. This concept is an application of Dantzig-Wolfe Decomposition. There are only a few constraints connecting these subproblems, namely the cover constraints. First we regard the LP relaxation of this problem and solve this via column generation. The resulting subproblem for each duty is a shortest path problem with resource constraints (SPPRC), which is also $\mathcal{NP}$-hard. For solving this subproblem, we have both a heuristic and an exact algorithm. In order to receive a total solution, we apply branch-and-price. We provide and discuss some branching strategies used for this procedure.

Most of the procedure is already developed by \cite{Kaiser}. We show the crucial results for the algorithm and discuss our adaptions in the path flow formulation, the algorithm solving the subproblems and the branch-and-price procedure. This adaptions make the optimal approach also cope with multi-leg cover constraints.

%########################################################################################################################################
%#
%#   Path Flow Formulation
%#
%########################################################################################################################################

\section{Path Flow Formulation}

We apply Dantzig-Wolfe Decomposition in order to create a path flow formulation of our problem. This is advantageous since the size of the arc flow formulation grows very fast with increasing problem size. We give only a short outline on the general procedure and then show the application of our problem.

\subsection{Dantzig-Wolfe Decomposition}

Dantzig-Wolfe Decomposition can be used in order to deal with large mixed-integer linear programs. It breaks the problem into smaller subproblems if the structure is suitable. This is the case if a large subset of the variables can be partitioned in a way such that the sets of occurring variables are disjoint for most of the constraints. The structure of the matrix for such a linear program looks as follows:
\begin{align*}
	\left(\begin{array}{cccccccccccc}
		\star  & \cdots & \star  & \star  & \cdots & \star  &        &        &        & \star  & \cdots & \star  \\
		\vdots & \ddots & \vdots & \vdots & \ddots & \vdots &        & \cdots &        & \vdots & \ddots & \vdots \\
		\star  & \cdots & \star  & \star  & \cdots & \star  &        &        &        & \star  & \cdots & \star  \\
		\hline
		\star  & \cdots & \star  & 0      & \cdots & 0      &        &        &        & 0      & \cdots & 0      \\
		\vdots & \ddots & \vdots & \vdots & \ddots & \vdots &        & \cdots &        & \vdots & \ddots & \vdots \\
		\star  & \cdots & \star  & 0      & \cdots & 0      &        &        &        & 0      & \cdots & 0      \\
		0      & \cdots & 0      & \star  & \cdots & \star  &        &        &        &        &        &        \\
		\vdots & \ddots & \vdots & \vdots & \ddots & \vdots &        & \ddots &        &        & \vdots &        \\
		0      & \cdots & 0      & \star  & \cdots & \star  &        &        &        &        &        &        \\
		       &        &        &        &        &        &        &        &        & 0      &        & 0      \\
		       & \vdots &        &        & \ddots &        &        & \ddots &        & \vdots & \ddots & \vdots \\
		       &        &        &        &        &        &        &        &        & 0      &        & 0      \\
		0      & \cdots & 0      &        &        &        & 0      & \cdots & 0      & \star  & \cdots & \star  \\
		\vdots & \ddots & \vdots &        & \cdots &        & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\
		0      & \cdots & 0      &        &        &        & 0      & \cdots & 0      & \star  & \cdots & \star  \\
	\end{array}\right)
\end{align*}

The subproblems emerge by considering only the constraints of a single set of this partition. The other constraints concerning the whole variable set are called linking constraints as they link the respective subproblems. The master problem considers the objective function in connection with the linking constraints. We then apply column generation for each of the subproblems separately. Starting with only a small set of feasible solutions, we successively generate further feasible solutions and include them to the master problem. Each feasible solution represents a column of the matrix representing the linear program. In the master problem, the actual formulation of the subproblems is not needed. Thus, we can extract the subproblems and solve them with specialized algorithms if they have an appropriate structure.

The column generation method is only able to solve linear program. Thus, we have to restate the integrality afterwards. How this is done is discussed later.

%----------------------------------------------------------------------------------------------------------------------------------------

\subsection{Application of the Decomposition}

In the original problem formulation, we regard only a single set of variables which model the entire flow of the vehicles. For the arc flow formulation, a single variable set is advantageous as the corresponding task graph stays small. In contrast to this, we extend the variable set in order to define smaller subproblems.

\paragraph{Identification of the Subproblems} \parfill

Consider a solution of the $\eqref{eq:MMILP}$. This solution can be decomposed in a set of separate vehicle duties. For each of these duties, the time and fuel restrictions can be applied individually. The only requirements that do not occur in the respective duties individually are the cover constraints. They guarantee that for each customer exactly one route is fulfilled and for each route, if it is fulfilled, each of its trips are fulfilled. Therefore the duty of each vehicle is a natural choice for the subproblem. We introduce $\left(x^v,z^v,e^v\right)$ for $v\in\mathcal{V}$ as the specific variables for each vehicle. With this we define the set of feasible vehicle duties as $X_v$ for $\vinV$.
\begin{align}
	X_v := \left\{\vphantom{\{0,1\}^A}\right. & \omit\rlap{$\displaystyle{(x,z,e)\in\left\{0,1\right\}^A \times \{0,1\}^{\left(A\cap\left(\mathcal{V}\cupdot\mathcal{T}\right)^2\right)\times\mathcal{R}} \times [0,1]^{\mathcal{V}\cupdot\mathcal{T}}|}$} \nonumber \\
	& \sum_{t\in\Nin(s)} x_{t,s} = \sum_{t\in\Nout(s)} x_{s,t} && \text{for all } s\in V\backslash\left\{d^{\operatorname{s}},d^{\operatorname{e}}\right\} \tag{\ref{eq:MMILP:flow}} \\
	& \sum_{s\in\Nin(t)} x_{s,v} = 1 \label{eq:Xv:vehicle} \\
	& \sum_{s\in\Nin(t)} x_{s,t} = 0 && \text{for all } t\in\mathcal{V}\backslash\{v\} \label{eq:Xv:other_vehicles} \\
	& \sum_{r\in\Rst} z_{s,r,t} \leq x_{s,t} & & \text{for all } t\in\mathcal{T}, s\in\Nin(t) \tag{\ref{eq:MMILP:refuel}} \\
	& e_s \leq f_s^0 & & \text{for all } s\in\mathcal{V} \tag{\ref{eq:MMILP:initial_fuel}} \\
	& 0 \leq e_s - \sum_{r\in\Rst} z_{s,r,t}\fd_{s,r} & & \text{for all } t\in\mathcal{T}, s\in\Nin(t) \tag{\ref{eq:MMILP:min_fuel}} \\
	& e_t \leq 1 - \ft_t - \sum_{r\in\Rst} z_{s,r,t}\fd_{r,t} & & \text{for all } t\in\mathcal{T}, s\in\Nin(t) \tag{\ref{eq:MMILP:max_fuel}} \\
	& \omit\rlap{$\displaystyle{e_t \leq e_s - x_{s,t}\left(f_{s,t}^{\operatorname{d}}+f_t^{\operatorname{t}}\right) - \sum_{r\in\Rst} z_{s,r,t}\left(\fd_{s,r}+\ft_r+\fd_{r,t}-\fd_{s,t}\right) + \left(1-x_{s,t}\right)}$} \nonumber \\
	& & & \text{for all } t\in\mathcal{T}, s\in\Nin(t) \tag{\ref{eq:MMILP:fuel_consumption}} \\
	& \left. \vphantom{\{0,1\}^A} \right\} \nonumber
\end{align}

Constraints $\eqref{eq:Xv:vehicle}$ and $\eqref{eq:Xv:other_vehicles}$ ensure that exactly vehicle $v$ is used in this formulation. We denote the set of feasible duties for any vehicle by $X:=\bigcup_{v\in\mathcal{V}}X_v$. Any feasible solution of $\eqref{eq:MMILP}$ can be decomposed into vehicle duties. This is guaranteed by $\eqref{eq:MMILP:vehicles}$ which forces the duties of the vehicles to be disjoint with respect to the trips. The only variables that are not considered in $X_v$ are the route variables $u_m$ which can be determined by the arc variables $x_{s,t}$. The objective function is additive with respect to the decomposition except for the route cost which we then consider explicitly. We write the cost for a configuration $\left(x^v,z^v,e^v\right)$ as $g\left(x^v,z^v,e^v\right)$.

The only constraints that are not ensured in $X_v$ are the cover constraints $\eqref{eq:MMILP:customer}$ and $\eqref{eq:MMILP:route}$. These are the linking constraints for the various subproblems. In summary, we can rewrite $\eqref{eq:MMILP}$ as
\begin{align}
	\min \quad & \sum_{v\in\mathcal{V}}g\left(x^v,z^v,e^v\right) + \sum_{m\in\mathcal{M}} u_m \croute_m \nonumber \\
	\text{s.t.} \quad & \sum_{m\in C^{-1}(c)} u_m = 1 && \text{for all } c\in\mathcal{C} \tag{\ref{eq:MMILP:customer}} \\
	& \sum_{v\in\mathcal{V}}\sum_{s\in\Nin(t)}x^v_{s,t} = u_m && \text{for all } m\in\mathcal{M},t\in m \label{eq:MMILP:linking}\\
	& \left(x^v,z^v,e^v\right)\in X_v && \text{for all } v\in\mathcal{V} \nonumber \\
	& u_m\in\{0,1\}^{\mathcal{M}} \nonumber
\end{align}

\paragraph{Reduction of the Master Problem} \parfill

Because of the introduction of variables for each vehicle, the resulting problem size is very large. For maintaining the master problem, not all information of $X_v$ are needed. In order to fulfill $\eqref{eq:MMILP:linking}$ we need only ${\sum_{s\in\Nin(t)} x_{s,t}}$, which is the set of trips served by a specific vehicle. Therefore, we define the linear mapping
\begin{align*}
	\psi:X\to\{0,1\}^{\mathcal{T}} && (x,z,e)\mapsto\left(\sum_{s\in\Nin(t)}x_{s,t}\right)_{t\in\mathcal{T}} \label{eq:psi}
\end{align*}

The dimension of the codomain of $\psi$ is much smaller than the dimension of the domain. We can rewrite $\eqref{eq:MMILP}$ by using $y^v:=\psi\left(x^v,z^v,e^v\right)$:
\begin{align*}
	\min \quad & \omit\rlap{$\displaystyle{\sum_{v\in\mathcal{V}}\min g\left(\psi^{-1}\left(y^v\right)\cap X_v\right) + \sum_{m\in\mathcal{M}}u_m\croute_m}$} \\
	\text{s.t.} \quad & \sum_{m\in C^{-1}(c)} u_m = 1 && \text{for all } c\in\mathcal{C} \tag{\ref{eq:MMILP:customer}} \\
	& \sum_{v\in\mathcal{V}}y^v_t = u_m && \text{for all } m\in\mathcal{M},t\in m \\
	& y^v\in \psi\left(X_v\right) && \text{for all } v\in\mathcal{V} \\
	& u_m\in\{0,1\} && \text{for all } m\in\mathcal{M}
\end{align*}

The mapping $\psi$ is not injective in general. Thus, there is more than one feasible duty that serves exactly the trips of $y^v$. These duties can have different cost. We therefore use the minimal resulting cost
\begin{align*}
	\min g\left(\psi^{-1}\left(y^v\right)\cap X_v\right) = \min \left\{g\left(x^v\right)|x^v\in X_v, \psi\left(x^v\right)=y^v\right\}
\end{align*}

This is the smallest cost of a vehicle duty that serves exactly the trips as indicated by the incidence vector $y^v$. We do not have to determine these costs now. As we will see later, the costs are a byproduct of solving the subproblems.

\paragraph{Column Generation} \parfill

We apply column generation to our problem. For every $v\in\mathcal{V}$, let $\Iv$ be an index set for the finitely many points in $\psi\left(X_v\right)$ and let the columns of $Y^v\in\mathbb{R}^{\mathcal{T}\times\Iv}$ be exactly those points. Let $G^v\in\mathbb{R}^{1\times\mathcal{I}}$ be the respective values of $\min g\left(\psi^{-1}(\cdot)\cap X_v\right)$. Then we can reformulate the master problem as
\begin{align*}
	\min \quad & \sum_{v\in\mathcal{V}}G^v\lambda^v + \sum_{m\in\mathcal{M}}u_m\croute_m \tag{IMP} \label{eq:IMP} \\
	\text{s.t.} \quad & \sum_{v\in\mathcal{V}} Y^v_{t,\cdot}\lambda^v = u_m && \text{for all } m\in\mathcal{M},t\in m \\
	& \sum_{m\in C^{-1}(c)} u_m = 1 && \text{for all } c\in\mathcal{C} \\
	& \sum_{i\in\Iv}\lambda_i^v=1 && \text{for all } v\in\mathcal{V}\\
	& \lambda^v\in\{0,1\}^{\Iv} && \text{for all } v\in\mathcal{V} \\
	& u_m\in\{0,1\} && \text{for all } m\in\mathcal{M}
\end{align*}

Then we regard the LP-relaxation of $\eqref{eq:IMP}$ by dropping the integrality constraints:
\begin{align*}
	\min \quad & \sum_{v\in\mathcal{V}}G^v\lambda^v + \sum_{m\in\mathcal{M}}u_m\croute_m \tag{LMP} \label{eq:LMP} \\
	\text{s.t.} \quad & \sum_{v\in\mathcal{V}} Y^v_{t,\cdot}\lambda^v = u_m && \text{for all } m\in\mathcal{M},t\in m \\
	& \sum_{m\in C^{-1}(c)} u_m = 1 && \text{for all } c\in\mathcal{C} \\
	& \sum_{i\in\Iv}\lambda_i^v=1 && \text{for all } v\in\mathcal{V}\\
	& \lambda^v\in\mathbb{R}_{\geq 0}^{\Iv} && \text{for all } v\in\mathcal{V} \\
	& u_m\geq 0 && \text{for all } m\in\mathcal{M}
\end{align*}

As next step, we reduce the size of the problem by considering only subsets $\Jv\subset\Iv$ of the feasible solutions for all $\vinV$ and formulate the relaxed restricted master problem:
\begin{align*}
	\min \quad & \sum_{v\in\mathcal{V}}G^v_{\Jv}\lambda^v + \sum_{m\in\mathcal{M}}u_m\croute_m \tag{LRMP} \label{eq:LRMP} \\
	\text{s.t.} \quad & \sum_{v\in\mathcal{V}} Y^v_{t,\Jv}\lambda^v = u_m && \text{for all } m\in\mathcal{M},t\in m \\
	& \sum_{m\in C^{-1}(c)} u_m = 1 && \text{for all } c\in\mathcal{C} \\
	& \sum_{i\in\Jv}\lambda_i^v=1 && \text{for all } v\in\mathcal{V}\\
	& \lambda^v\in\mathbb{R}_{\geq 0}^{\Jv} && \text{for all } v\in\mathcal{V} \\
	& u_m\geq 0 && \text{for all } m\in\mathcal{M}
\end{align*}

Finally, we regard the dual relaxed restricted master problem. For this, we introduce dual variables $\gamma\in\mathbb{R}^{\mathcal{T}}$, $\mu\in\mathbb{R}^{\mathcal{V}}$ and $\eta\in\mathbb{R}^{\mathcal{C}}$. The dual problem is:
\begin{align}
	\max \quad & \sum_{c\in\mathcal{C}}\eta_c + \sum_{v\in\mathcal{V}}\mu_v \tag{DLRMP} \label{eq:DLRMP} \\
	\text{s.t.} \quad & \sum_{t\in\mathcal{T}} Y^v_{t,i}\gamma_t + \mu_v \leq G^v_i && \text{for all } v\in\mathcal{V},i\in\Jv \label{eq:DLRMP:vehicle} \\
	& \eta_{C(m)} - \sum_{t\in m}\gamma_t \leq \croute_m && \text{for all } m\in\mathcal{M} \label{eq:DLRMP:route} \\
	& \gamma\in\mathbb{R}^{\mathcal{T}} \nonumber \\
	& \mu\in\mathbb{R}^{\mathcal{V}} \nonumber \\
	& \eta\in\mathbb{R}^{\mathcal{C}} \nonumber
\end{align}

%----------------------------------------------------------------------------------------------------------------------------------------

\subsection{Solving the Relaxed Master Problem}

The size of the index set $\Iv$ of all feasible solutions of $X_v$ can be exponential in the input size. Therefore, the formulation $\eqref{eq:IMP}$ is hard, even the relaxed version $\eqref{eq:LMP}$ is hard. In order to tackle the problem, we first consider a small subset $\Jv\subset\Iv$ of the index set. We solve the problem $\eqref{eq:LRMP}$ where only duties from the restricted set are allowed. Since $\Jv$ is small, it is easier to solve the problem. Originating from this solution, we iteratively enlarge $\Jv$ and solve $\eqref{eq:LRMP}$ until the solution is an optimal solution of $\eqref{eq:LMP}$. For this method arise the following questions.
\begin{enumerate}
	\item{Does this procedure come up with an optimal solution in finitely many steps?}
	\item{How do we find columns to add?}
	\item{How do we check for optimality in $\eqref{eq:LMP}$?}
\end{enumerate}

If we iteratively add columns to $\Jv$, we finally have $\Jv=\Iv$ after a finite number of steps since $\Iv$ is a finite set. When this is reached, the problems $\eqref{eq:LRMP}$ and $\eqref{eq:LMP}$ are equivalent and thus the solution is optimal. Obviously, this behavior is not desirable as we do not want to solve the unrestricted problem. Thus, we hope to receive an optimal solution earlier.

We can check for optimality and find columns to add by using the dual problems of the restricted and the unrestricted problem. Consider a solution $\left(\lambda^v\right)_{\vinV}$ of $\eqref{eq:LRMP}$ and its corresponding dual solution $\left(\gamma^*,\mu^*,\eta^*\right)$ which is feasible in $\eqref{eq:DLRMP}$. We want to check whether $\left(\lambda^v\right)_{\vinV}$ is an optimal solution of the unrestricted problem $\eqref{eq:LMP}$. Due to strong duality, this is the case if and only if $\left(\gamma^*,\mu^*,\eta^*\right)$ is feasible in the unrestricted dual problem (DLMP).

We therefore consider the constraints of the dual problems. $\eqref{eq:DLRMP:route}$ are equivalent in both formulations. The constraints $\eqref{eq:DLRMP:vehicle}$ read as follows in the unrestricted case
\begin{align}
	\sum_{t\in\mathcal{T}} Y^v_{t,i}\gamma_t + \mu_v \leq G^v_i && \text{for all } \vinV,i\in\Iv \label{eq:DLMP:vehicle}
\end{align}

Since $\left(\gamma^*,\mu^*,\eta^*\right)$ is a solution of the restricted problem, $\eqref{eq:DLMP:vehicle}$ is fulfilled for all $i\in\Jv$. It remains to check $\Iv\backslash\Jv$ which leads to the subproblem
\begin{align}
	\text{Find } i\in\Iv\backslash\Jv && \text{ s.t.} && \sum_{t\in\mathcal{T}}Y^v_{t,i}\gamma^*_t + \mu^*_v > G^v_i && \text{for } \vinV
\end{align}

\paragraph{Identification of the Subproblem} \parfill

Recall the definitions ${G^v_i = \min g\left(\psi^{-1}\left(Y^v_i\right)\cap X_v\right)}$ and ${Y^v_i = \psi(x,z,e)}$ for the respective ${(x,z,e)\in X_v}$. Using this, we can rewrite the subproblem to
\begin{align*}
	\min \quad & g\left(x,z,e\right)-\sum_{t\in\mathcal{T}}\sum_{s\in\Nin(t)}x_{s,t}\gamma^*_t \tag{$\operatorname{SP}_v$} - \mu^*_v \label{eq:SPv} \\
	\text{s.t.} \quad & \left(x,z,e\right)\in X_v
\end{align*}

Actually, the term $g(x,z,e)$ would be ${\min g\left(\psi^{-1}\left(\psi(x,z,e)\right)\cap X_v\right)}$. The following result shows that this distinction is not necessary as this is done implicitly be solving the subproblem.

\begin{lemma}

For $\vinV$, an optimal solution ${\left(x^*,z^*,e^*\right)\in X_v}$ to the subproblem $\eqref{eq:SPv}$ fulfills
\begin{align*}
	g\left(x^*,z^*,e^*\right) = \min g\left(\psi^{-1}\left(\psi\left(x^*,z^*,e^*\right)\right)\cap X_v\right).
\end{align*}

In other words, the duty $\left(x^*,z^*,e^*\right)$ has the smallest possible cost under all duties which serve the same set of trips.

\end{lemma}

This lemma is proven by \cite[pp.~42-43]{Kaiser} and holds for our case, too.

How the subproblem $\eqref{eq:SPv}$ is solved, is shown in \Cref{sec:solving_subproblem}. As mentioned before, the cost $G^v_i$ are also determined by solving the subproblem. We receive a solution $(x,z,e)$ of $\eqref{eq:SPv}$ for all $\vinV$ and simultaneously the cost $g(x,z,e)$. If we then add the corresponding duty to $\Jv$, we can easily use the determined cost for $G^v$.

\paragraph{Updating the Index Set} \parfill

The value of a duty as determined in the subproblem is called reduced cost. As long as there exists a violated constraint in the dual problem, there exists a column with negative reduced cost. This is used for deciding if a duty is added to the index set. First, we solve $\eqref{eq:DLRMP}$ and receive a solution $\left(\gamma^*,\mu^*,\eta^*\right)$. With this we solve $\eqref{eq:SPv}$ for all $\vinV$ and receive solutions $\left(x^v,z^v,e^v\right)$. We know that all of these duties with negative reduced cost correspond to a violated constraint in (DLMP). Thus we consider these duties in the next step. For all $\vinV$ with $\operatorname{value}\left(x^v,z^v,e^v\right)<0$ we update the index set
\begin{align*}
	\Jv\gets\Jv\cup\{i\} && Y^v_{\cdot,i}\gets\psi\left(x^v,z^v,e^v\right) && G^v_i\gets g\left(x^v,z^v,e^v\right)
\end{align*}

If $\operatorname{value}\left(x^v,z^v,e^v\right)\geq 0$ for all $\vinV$, then the dual solution $\left(\gamma^*,\mu^*,\eta^*\right)$ is feasible in (DLMP) and the corresponding primal solution $\left(\lambda^v\right)_{\vinV}$ is an optimal solution of the relaxed master problem $\eqref{eq:LMP}$.

\paragraph{Initial Solution} \parfill

For starting the column generation method, an initial index set is required for $\Jv$ for all $\vinV$. The index sets have to be feasible, \ie each occurring duty is feasible and there is a solution satisfying the cover constraints $\eqref{eq:MMILP:customer}$ and $\eqref{eq:MMILP:route}$ using only duties out of $\bigcup_{\vinV}\Jv$. Otherwise the restricted problem is infeasible and its dual problem is unbounded. Then we do not receive a solution $\left(x^*,z^*,e^*\right)$ of $\eqref{eq:DLRMP}$ with which we define the subproblems. As an initial solution we use a heuristical solution of the problem, as we have developed in \Cref{ch:heuristics}.

Note that this procedure only provides a solution of the LP-relaxation of the master problem. In \Cref{sec:solving_masterproblem} we show how we receive a solution of $\eqref{eq:IMP}$.

%########################################################################################################################################
%#
%#   Solving of the Subproblems
%#
%########################################################################################################################################

\section{Solving of the Subproblems}
\label{sec:solving_subproblem}

In every step of the master problem, we solve the subproblem $\eqref{eq:SPv}$ for each vehicle $\vinV$. This subproblem is equivalent to the Shortest Path Problem with Resource Constraints (SPPRC). A vehicle duty is expressed as $\ds$-$\de$-path whose first vertex is the respective vehicle $v$. The main resource is the fuel state of the vehicle, where refuel stations have negative fuel consumption. The goal is to find a feasible path with negative reduced cost which is then the new duty. Besides fuel, in the algorithm are used additional resources which describe what multimodal routes are served in this duty.

\subsection{Shortest Path Problem with Resource Constraints}

In this section, we summarize the crucial results in order to show a label-setting algorithm which solves the (SPPRC) optimally. The respective definitions and the algorithm are shown in detail in \cite{Kaiser} and \cite{Irnich_Desaulniers}. The (SPPRC) is a generalization of the Shortest Path Problem and is $\mathcal{NP}$-hard, as shown in \cite[p.307]{Handler_Zang}. The problem is given by a graph, a set of resources and a relation on every arc that specifies the change of resources along its way. 

\begin{definition}[Graph with resource constraints]

We call ${H:=\left(V_H,A_H,\sqsubseteq,I,\REF\right)}$ a graph with resource constraints for a set of resources $\mathcal{U}$ if
\begin{enumerate}
	\item{$\left(V_H,A_H\right)$ is a directed graph with vertex set $V_H$ and arc set $A_H$.}
	\item{$\sqsubseteq\in\left\{\leq,=,\geq\right\}^{\mathcal{U}}$ is a vector of resource relations and is called the resource dominance relation.}
		For two resources ${r,\tilde{r}\in\mathbb{R}^{\mathcal{U}}}$, we write ${r\sqsubseteq\tilde{r}}$ if ${r_u\sqsubseteq_u \tilde{r}_u}$ for all $u\in\mathcal{U}$ and say that $\tilde{r}$ dominates $r$. The subset of maximal vectors of a set $R\subseteq\mathbb{R}^{\mathcal{U}}$ with respect to $\sqsubseteq$ is denoted by
		\begin{align*}
			\max_{\sqsubseteq} R := \left\{r\in R\mid \forall\tilde{r}\in R: r\sqsubseteq\tilde{r}\Rightarrow r=\tilde{r}\right\}
		\end{align*}
		The closed cone of resource vectors less than or equal to zero with respect to $\sqsubseteq$ is denoted by
		\begin{align*}
			\mathbb{R}^{\mathcal{U}}_{\sqsubseteq 0} := \left\{r\in\mathbb{R}^{\mathcal{U}}\mid r\sqsubseteq 0_{\mathcal{U}}\right\}
		\end{align*}
	\item{$I\subseteq\mathbb{R}^{\mathcal{U}}$ is the Cartesian product of closed intervals of $\mathbb{R}$.}
		The projection onto a single resource $u\in\mathcal{U}$ denoted by $\Pi_u(I)$ is called its resource window. If $\Pi_u(I)=\mathbb{R}$ for some resource $u\in\mathcal{U}$ it is called unrestricted.
	\item{$\REF = \left(\REF_{u,w}\right)_{(v,w)\in A_H}$}
		is a vector of binary relations ${\REF_{v,w}\subseteq I\times I}$ for all ${(v,w)\in A_H}$ such that the set of vectors related to some ${r^v\in I}$
		\begin{align*}
			\REF_{v,w}\left(r^v\right) := \left\{r^w\in I\mid \left(r^v,r^w\right)\in\REF_{v,w}\right\}
		\end{align*}
		is closed, has a finite set of maximal vectors ${\max_{\sqsubseteq}\REF_{v,w}\left(r^v\right)}$ and fulfills
		\begin{align*}
			\forall r^w,\tilde{r}^w\in I,r^w\sqsubseteq\tilde{r}^w : \tilde{r}^w\in\REF_{v,w}\left(r^v\right) \Rightarrow r^w\in\REF_{v,w}\left(r^v\right).
		\end{align*}
		$\REF_{v,w}$ is called the resource extension function with respect to $\sqsubseteq$ on the arc $(v,w)\in A_H$.
\end{enumerate}
	
\end{definition}

The resource vectors are assigned to the vertices of the graph. They describe the absolute amount of available resources at that vertex.

The resource dominance relation is a partial order on $\mathbb{R}^{\mathcal{U}}$. If two resource vectors are comparable, then the dominating vector is always preferable to the other. If it is desirable to have a high quantity of a resource, the resource relation is set to $\leq$, \eg for the fuel resource. Otherwise it is set to $\geq$, \eg for the modeling cost resource. If no general relation holds, it is set to $=$. The resource extension function models the change of the resource vectors along the arcs. It relates a resource vector to all possible outcomes when traveling along this arc. 

\begin{definition}[Monotone resource extension function]

A resource extension function ${\REF_{v,w}\subseteq I\times I}$ with respect to $\sqsubseteq$ is called monotone if
\begin{align*}
	\forall r^v,\tilde{r}^v\in I, r^v\sqsubseteq\tilde{r}^v : \REF_{v,w}\left(r^v\right)\subseteq\REF_{v,w}\left(\tilde{r}^v\right)
\end{align*}
holds.

\end{definition}

The monotonicity is important for the consistency. If a resource vector is dominated by another, then there are not more possible outcomes than for the dominating one.

After introducing the graph, we define resource-feasible paths on this graph.

\begin{definition}[Resource-feasible path]

Let ${H=\left(V_H,A_H,\sqsubseteq,I,\REF\right)}$ be a graph with resource constraints. A path ${P:=\left(v_0,\dots,v_n\right)}$ of length ${n\in\mathbb{N}_0}$ in $H$ is called resource-feasible if
\begin{align*}
	\exists r^{v_i}\in I,i\in\{0,\dots,n\}: \left(r^{v_{i-1}},r^{v_i}\right)\in\REF_{v_{i-1},v_i} \forall i\in\{1,\dots,n\}
\end{align*}
holds. We say $\left(r^v\right)_{v\in P}$ witnesses resource-feasibility of $P$.

\end{definition}

The witnessing resource vectors $\left(r^v\right)_{v\in\mathcal{P}}$ are the resources along this path, \eg the fuel state of the respective trips of a vehicle duty.

\paragraph{Contraction and Inversion} \parfill

We define the actions \enquote{contraction of an arc} and \enquote{inversion of a graph} in order to apply them to our problem.

\begin{definition}[Contraction]

${H=\left(V_H,A_H,\sqsubseteq,I,\REF\right)}$ be a graph with resource constraints, ${(v,w)\in A_H}$ be the only arc leaving some vertex $v\in V_H$ and $\REF_{v,w}$ be monotone.
\begin{enumerate}
	\item
For $(u,v)\in A_H$, the concatenation of resource extension functions is defined as
\begin{align*}
	\REF_{v,w}\circ\REF_{u,v} := \left\{\vphantom{\REF_{v,w}}\right. & \left(r^u,r^w\right)\in I\times I\mid \exists r^v\in I: \\
	& \left.\left(r^u,r^v\right)\in\REF_{u,v}\land\left(r^v,r^w\right)\in\REF_{v,w}\right\}
\end{align*}
	\item
The graph with resource constraints ${\widehat{H} := \left(V_{\widehat{H}},A_{\widehat{H}},\sqsubseteq,I,\widehat{\REF}\right)}$ which results from $H$ by contracting the arc $(v,w)$ is defined by the vertex set ${V_{\widehat{H}} := V_H\backslash\{v\}}$, the arc set
\begin{align*}
	A_{\widehat{H}} := \left(A_H\cap V^2_{\widehat{H}}\right) \cup \left\{(u,w)\mid (u,v)\in A_H\right\},
\end{align*}

and the resource extension function ${\left(\REF_a\right)_{a\in A_{\widehat{H}}}}$, where
\begin{align*}
	\widehat{\REF}_a :=
	\begin{cases}
		\REF_{u,w}\cup\left(\REF_{v,w}\circ\REF_{u,v}\right) & \text{if } \exists u\in V_{\widehat{H}}: a=(u,w) \\
		\REF_a & \text{otherwise}
	\end{cases}
\end{align*}

for all ${a\in A_H}$. $\REF_{u,w}$ and $\REF_{u,v}$ are considered to be the empty relation $\emptyset$ if ${(u,w)\not\in A_H}$ or ${(u,v)\not\in A_H}$, respectively.

\end{enumerate}

\end{definition}

In \cite[p.~79]{Kaiser} is proven that for a resource-feasible path $P$ in the original graph $H$ there is a resource-feasible path $\widehat{P}$ in the contracted graph $\widehat{H}$ and vice versa such that $P$ and $\widehat{P}$ cover the same vertices of $V_H\backslash\{v\}$. We need contraction since we have resources on both the vertices and the arcs in our problem. 

\begin{definition}[Inversion]

\begin{enumerate}
	\item{A resource extension function}
$\REF_{v,w}$ with respect to $\sqsubseteq$ is called invertible if the inverted relation
\begin{align*}
	\REF^{-1}_{v,w} := \left\{\left(r^w,r^v\right)\mid\left(r^v,r^w\right)\in\REF_{v,w}\right\}
\end{align*}
is a resource extension function with respect to the inverted dominance relation~$\sqsupseteq$. $\REF^{-1}_{v,w}$ is called the inversion of $\REF_{v,w}$.
	\item{Let}
${H := \left(V_H,A_H,\sqsubseteq,I,\REF\right)}$ be a graph with resource constraints and invertible resource extension functions.

The inversion of $H$ is defined to be the graph
\begin{align*}
	H^{-1} := \left(V_H,A^{-1}_H,\sqsupseteq,I,\REF^{-1}\right)
\end{align*}
with inverted arc set ${A_H^{-1}:=\left\{(w,v)\in V_H^2\mid (v,w)\in A_H\right\}}$ and inverted resource extension functions ${\REF^{-1} := \left(\REF^{-1}_{v,w}\right)_{(w,v)\in A^{-1}_H}}$.
\end{enumerate}

\end{definition}

In \cite[p.~83]{Kaiser} is proven that in a graph $H$ with invertible resource extension functions, a path ${P:=\left(v_0,\dots,v_n\right)}$ is resource-feasible with witnessing resource vectors ${\left(r^v\right)_{v\in P}}$ if and only if ${P^{-1}:=\left(v_n,\dots,v_0\right)}$ is resource-feasible in the inverted graph $H^{-1}$ with witnessing resource vectors $\left(r^v\right)_{v\in P^{-1}}$. We need inversions in order to improve the behavior of the algorithm. Using inversions we can apply the algorithm once for all subproblems and do not have to solve each subproblem separately.

\paragraph{Label-Setting Algorithm} \parfill

We solve the (SPPRC) via a label-setting algorithm. Previously in this section, we have added resources to the graph in order to restrict the set of feasible paths. Since we do not have a cost function, finding an optimal path is not straight-forward. We do not have a shortest path but multiple resource-feasible paths. We use the resource dominance relation $\sqsubseteq$ to compare different paths. If a path is dominated by another, it is not preferable and therefore not considered in the solution. If two paths are not comparable, we cannot decide which one is more preferable. This leads to the concept of Pareto-optimality.

\begin{definition}[Pareto-optimal paths]

Let ${H:=\left(V_H,A_H,\sqsubseteq,I,\REF\right)}$ be a graph with resource constraints. Let $P$ be a resource-feasible $v$-$w$-path in $H$.

$P$ is called Pareto-optimal if there exist witnesses $\left(r^u\right)_{u\in P}$ for the resource-feasibility of $P$ such that for every resource-feasible $v$-$w$-path $Q$ in $H$ with witnessing resource vectors $\left(\tilde{r}^u\right)_{u\in Q}$ fulfilling ${\tilde{r}^v = r^v}$
\begin{align*}
	r^w\sqsubseteq \tilde{r}^w \Rightarrow r^w = \tilde{r}^w
\end{align*}

holds. We say that the resource vectors $\left(r^u\right)_{u\in P}$ witness Pareto-optimality of $P$.

\end{definition}

In general, there can be exponentially many paths in a graph with respect to its size. It is further possible that the witnessing resource vectors are not comparable. Hence, there can be an exponential number of Pareto-optimal paths in a graph. This fact gives a feeling why (SPPRC) is $\mathcal{NP}$-hard.

The idea of the algorithm is to start with a trivial path, consisting of one single vertex. We then extend the paths while we maintain resource-feasibility and Pareto-optimality for all paths. Finally, we receive Pareto-optimal paths from the starting vertex to all vertices. The algorithm works on the concept of Dynamic Programming.

\begin{algorithm}[hbt]
	\SetAlgoLined
	\KwIn{graph with resource constraints ${H:=\left(V_H,A_H,\sqsubseteq,I,\REF\right)}$, topological sorting ${v_0,\dots,v_n}$ of $V_H$ and initial resource vector $r^{v_0}$}
	\KwOut{shortest path tree rooted at $\left(v_0,r^{v_0}\right)$ encoded by $\delta$}
	$\mathcal{P}_{v_0}\gets\left\{r^{v_0}\right\}$ \;
	$\delta\left(v_0,r^{v_0}\right)\gets\emptyset$ \;
	\lForEach{$i\in\left\{1,\dots,n\right\}$}{$\mathcal{P}_{v_i}\gets\emptyset$}
	\ForEach{$i=0,\dots,n$}{
		\ForEach{$r^{v_i}\in\mathcal{P}_{v_i}$}{
			\ForEach{$w\in\operatorname{N}^+_H\left(v_i\right)$}{
				$\mathcal{P}\gets\max_{\sqsubseteq}\REF_{v_i,w}\left(r^{v_i}\right)$ \;
				\lForEach{$r^w\in\mathcal{P}$}{$\delta\left(w,r^w\right)\gets\left(v_i,r^{v_i}\right)$}
				$\mathcal{P}_w\gets\mathcal{P}_w\cup\mathcal{P}$ \;
				$\mathcal{P}_w\gets\max_{\sqsubseteq}\mathcal{P}_w$ \;
			}
		}
	}
	\Return{$\delta$}
	\caption{Label-setting algorithm for acyclic graphs with resource constraints}
\end{algorithm}

We have a graph with resource constraints, a topological sorting of the vertices and an initial resource vector as input. The graph has to be acyclic. A topological sorting ${\left\{v_0,\dots,v_n\right\}}$ means that there are no $i<j$ with ${\left(v_j,v_i\right)\in A_H}$. Start with vertex $v_0$ and initial resource vector $r^{v_0}$, we treat the vertices successively in topological order. For each vertex $v\in V_H$ and for each computed Pareto-optimal $v_0$-$v$-path, we try to extend the path feasibly by a single vertex. If a path is found, we add a label to the extending vertex and update the mapping $\delta$ in order to identify the origin of the extension. At the end, we receive the mapping $\delta$ which identifies all resource-feasible Pareto-optimal $v_0$-$v$-paths for each vertex $v\in V_H$.

%----------------------------------------------------------------------------------------------------------------------------------------

\subsection{Strengthening Inequalities}

Before we apply the previously stated algorithm to the subproblem, we want to insert additional valid inequalities. These are not necessary but may improve the column generation process. In the original problem, we have the linking constraints $\eqref{eq:MMILP:customer}$ and $\eqref{eq:MMILP:route}$ which ensure that for every customer exactly one route is fulfilled. These constraints cannot be moved into the subproblems since the customers can be satisfied by different vehicles. It is even likely that two trips of the same route are fulfilled by different vehicles.

Nevertheless, we can identify duties that are infeasible with respect to the cover constraints. This is the case, if a vehicle fulfills two trips that belong to the same costumer but not to the same route. If this duty is part of the overall solution, it is not possible that $\eqref{eq:MMILP:customer}$ and $\eqref{eq:MMILP:route}$ are fulfilled simultaneously. Therefore, we want to prevent such a duty from being added to the column set.

In order to use the inequalities, we have to introduce decision variables $u_m\in\{0,1\}$ for $m\in\mathcal{M}$. We insert the following inequalities to $\eqref{eq:SPv}$ for each $\vinV$. They are not necessary since they are implied by the cover constraints of the master problem, but they strengthen formulation of the subproblem.
\begin{align}
	& \sum_{m\in C^{-1}(c)} u_m \leq 1 && \text{for all } c\in\mathcal{C} \label{eq:SPv:customer} \\
	& \sum_{s\in\Nin(t)} x_{s,t} \leq u_m && \text{for all } m\in\mathcal{M}, t\in m \label{eq:SPv:route} \\
	%& u_m\in\{0,1\} && \text{for all } m\in\mathcal{M} \label{eq:SPv:um}
\end{align}

These constraints ensure that for every customer at most one route can be fulfilled. Note that $\eqref{eq:SPv:customer}$ is also valid with equality. Adding these constraints possibly makes the subproblems harder to solve, but improves the behavior in the master problem since there are no duties added that are infeasible from the very beginning. If the addition is beneficial for the overall process, is not known in advance.

%----------------------------------------------------------------------------------------------------------------------------------------

\subsection{Determination of the Resources}

The only resource that we have used so far is the fuel resource. We use the index \emph{fuel} in our resource vector. The fuel is in the interval $[0,1]$ for the fuel level where $0$ means that the vehicle has no fuel and $1$ that the vehicle is completely fueled. A higher fuel level is preferable, hence the resource relation for fuel is $\leq$.

Since we have no objective function in this problem, we model the reduced cost as an additional resource. We introduce the index \emph{redcost} in order to keep track of the reduced cost of a duty. The reduced cost is unrestricted and the reduced cost is minimized, thus we set the resource window to $\mathbb{R}$ and the resource relation to $\geq$.

An additional resource is the number of trips that a vehicle fulfills. We call it the length of a duty and use the index \emph{length}. This resource is not necessary for the subproblem but advantageous for the branch-and-bound procedure as we see in \Cref{sec:solving_masterproblem}. The length of a duty lies in the interval $[0,|\mathcal{T}|]$. Comparing two duties with different lengths, it is not clear which of them is preferable. Thus the resource relation is $=$.

In order to ensure the constraints $\eqref{eq:SPv:customer}$ and $\eqref{eq:SPv:route}$ we use a resource for every multimodal route. We use the respective $m\in\mathcal{M}$ as index for the route resource. This resource indicates whether a trip of this route is fulfilled within this duty, therefore the resource window is $[0,1]$. Similar to the duty length is is not possible to compare different route resources, thus the resource relation is $=$.

Altogether, we consider resources ${\mathcal{U} := \left\{\operatorname{redcost},\operatorname{fuel},\operatorname{length}\right\}\cupdot\mathcal{M}}$ in the resource window
\begin{align*}
	I := \mathbb{R}\times[0,1]\times[0,|\mathcal{T}|]\times[0,1]^{\mathcal{M}}\subseteq\mathbb{R}^{\mathcal{U}}
\end{align*}

A resource vector $r\in I$ consists of the reduced cost ${r_{\operatorname{redcost}}\in\mathbb{R}}$, the fuel level ${r_{\operatorname{fuel}}\in[0,1]}$, the duty length ${r_{\operatorname{length}}\in[0,|\mathcal{T}|]}$ and the route resources ${r_{\mathcal{M}}\in[0,1]^{\mathcal{M}}}$ in this order. The resource relation vector is given by ${\sqsubseteq := \left(\geq,\leq,=,=,\dots,=\right)}$.

These resources coincide in large parts with the formulation in \cite{Kaiser}. They use resources for each costumer instead of route resources in order to ensure the single-leg cover constraints. This is the only adaption in this section and the next section.

%----------------------------------------------------------------------------------------------------------------------------------------

\subsection{Determination of the Resource Extension Function}
\label{sec:ref}

%----------------------------------------------------------------------------------------------------------------------------------------

\subsection{Improvement of the Algorithm}

%########################################################################################################################################
%#
%#   Solving of the Master Problem
%#
%########################################################################################################################################

\section{Solving of the Master Problem}
\label{sec:solving_masterproblem}

%########################################################################################################################################
%#
%#   Variants of the Problem Formulation
%#
%########################################################################################################################################

\section{Variants of the Problem Formulation}

\subsection{Master Problem with Route Choice Restriction}

Remember the formulation from before:

\begin{align*}
	\min \quad & \sum_{v\in\mathcal{V}}\min g\left(\psi^{-1}\left(y^v\right)\cap X_v\right) + \sum_{m\in\mathcal{M}}u_m\croute_m \\
	\text{s.t.} \quad & \sum_{m\in C^{-1}(c)} u_m = 1 && \text{for all } c\in\mathcal{C} \tag{\ref{eq:MMILP:customer}} \\
	& \sum_{v\in\mathcal{V}}y^v_t = u_m && \text{for all } m\in\mathcal{M},t\in m \\
	& y^v\in \psi\left(X_v\right) && \text{for all } v\in\mathcal{V} \\
	& u_m\in\{0,1\} && \text{for all } m\in\mathcal{M}
\end{align*}

The constraints $\eqref{eq:MMILP:customer}$ depend only on $u_m$. Therefore, we create another subproblem for the choice of routes. We define the set of feasible route choices as follows:

\begin{align*}
	\hat{X} := \left\{\{0,1\}^{\mathcal{M}}|\sum_{m\in C^{-1}(c)} u_m = 1 \text{ for all } c\in\mathcal{C}\right\}
\end{align*}

We introduce variable $\hat{u}$ and the respective route cost function $\hat{g}$ and rewrite $\eqref{eq:MMILP}$ again:

\begin{align*}
	\min \quad & \sum_{v\in\mathcal{V}} \min g\left(\psi^{-1}\left(y^v\right)\cap X_v\right) + \hat{g}\left(\hat{u}\right) \\
	\text{s.t.} \quad & \sum_{v\in\mathcal{V}}y_t^v = u_m && \text{for all } m\in\mathcal{M},t\in m \\
	& y^v\in \psi\left(X_v\right) && \text{for all } v\in\mathcal{V} \\
	& \hat{u}\in\hat{X}
\end{align*}

\paragraph{Column Generation} \parfill

For every $v\in\mathcal{V}$, let $\Iv$ be an index set for the finitely many points in $\psi\left(X_v\right)$ and let the columns of $Y^v\in\mathbb{R}^{\mathcal{T}\times\Iv}$ be exactly those points. Let $\Ihat$ be an index set for the finitely many points in $\hat{X}$ and let the columns of $\hat{Y}\in\mathbb{R}^{\mathcal{M}\times\hat{\mathcal{I}}}$ be exactly those points. Let $G^v\in\mathbb{R}^{1\times\mathcal{I}}$ be the respective values of $\min g\left(\psi^{-1}(\cdot)\cap X_v\right)$ and $\hat{G}\in\mathbb{R}^{1\times\Ihat}$ be the respective route costs. Then we can reformulate the master problem as

\begin{align*}
	\min \quad & \sum_{v\in\mathcal{V}}G^v\lambda^v + \hat{G}\hat{\lambda} \tag{IMMP} \\
	\text{s.t.} \quad & \sum_{v\in\mathcal{V}} Y^v_{t,\cdot}\lambda^v = \hat{Y}_{m,\cdot}\hat{\lambda} && \text{for all } m\in\mathcal{M},t\in m \\
	& \sum_{i\in\Iv}\lambda_i^v=1 && \text{for all } v\in\mathcal{V}\\
	& \sum_{i\in\Ihat}\hat{\lambda}_i= 1 \\
	& \lambda^v\in\{0,1\}^{\Iv} && \text{for all } v\in\mathcal{V} \\
	& \hat{\lambda}\in\{0,1\}^{\Ihat}
\end{align*}

We regard the LP-relaxation by dropping the integrality constraints:

\begin{align*}
	\min \quad & \sum_{v\in\mathcal{V}}G^v\lambda^v + \hat{G}\hat{\lambda} \tag{LMMP} \label{eq:LMMP} \\
	\text{s.t.} \quad & \sum_{v\in\mathcal{V}} Y^v_{t,\cdot}\lambda^v = \hat{Y}_{m,\cdot}\hat{\lambda} && \text{for all } m\in\mathcal{M},t\in m \\
	& \sum_{i\in\Iv}\lambda_i^v=1 && \text{for all } v\in\mathcal{V}\\
	& \sum_{i\in\Ihat}\hat{\lambda}_i= 1 \\
	& \lambda^v\in\mathbb{R}_{\geq 0}^{\Iv} && \text{for all } v\in\mathcal{V} \\
	& \hat{\lambda}\in\mathbb{R}_{\geq 0}^{\Ihat}
\end{align*}

We reduce the size by considering only subsets $\Jv\subset\Iv$ and $\hat{\mathcal{J}}\subset\Ihat$ and formulate the relaxed restricted master problem:

\begin{align*}
	\min \quad & \sum_{v\in\mathcal{V}}G^v_{\Jv}\lambda^v + \hat{G}_{\hat{\mathcal{J}}}\hat{\lambda} \tag{LRMMP} \\
	\text{s.t.} \quad & \sum_{v\in\mathcal{V}} Y^v_{t,\Jv}\lambda^v = \hat{Y}_{m,\hat{\mathcal{J}}}\hat{\lambda} && \text{for all } m\in\mathcal{M},t\in m \\
	& \sum_{i\in\Jv}\lambda_i^v=1 && \text{for all } v\in\mathcal{V}\\
	& \sum_{i\in\hat{\mathcal{J}}}\hat{\lambda}_i= 1 \\
	& \lambda^v\in\mathbb{R}_{\geq 0}^{\Jv} && \text{for all } v\in\mathcal{V} \\
	& \hat{\lambda}\in\mathbb{R}_{\geq 0}^{\hat{\mathcal{J}}}
\end{align*}

For the dual relaxed restricted master problem, we introduce dual variables $\gamma\in\mathbb{R}^{\mathcal{T}}$, $\mu\in\mathbb{R}^{\mathcal{V}}$ and $\alpha\in\mathbb{R}$. The dual problem is:

\begin{align*}
	\max \quad & \sum_{v\in\mathcal{V}}\mu_v + \alpha \tag{DLRMMP} \label{eq:DLRMMP} \\
	\text{s.t.} \quad & \sum_{t\in\mathcal{T}} Y^v_{t,i}\gamma_t + \mu_v \leq G^v_i && \text{for all } v\in\mathcal{V},i\in\Jv \\
	& \alpha - \sum_{m\in\mathcal{M}}\sum_{t\in m}\hat{Y}_{m,i}\gamma_t \leq \hat{G}_i && \text{for all } i\in\hat{\mathcal{J}} \\
	& \gamma\in\mathbb{R}^{\mathcal{T}} \\
	& \mu\in\mathbb{R}^{\mathcal{V}} \\
	& \alpha\in\mathbb{R}
\end{align*}

\paragraph{Solving of the Relaxed Master Problem} \parfill

Let $\left(\gamma^*,\mu^*,\alpha^*\right)$ be a solution of $\eqref{eq:DLRMMP}$ with $\Jv\subset\Iv$ for all $v\in\mathcal{V}$ and $\hat{\mathcal{J}}\subset\Ihat$. 

We want to find out whether $\left(\gamma^*,\mu^*,\alpha^*\right)$ corresponds to an optimal solution of $\eqref{eq:LMMP}$. This is the case if it is feasible for the dual relaxed master problem, i.e. the following constraints hold for the entire sets $\Iv$ and $\Ihat$. This means, the following equations hold for $\left(\gamma^*,\mu^*,\alpha^*\right)$:

\begin{align}
	& \sum_{t\in\mathcal{T}} Y^v_{t,i}\gamma^* + \mu^*_v \leq G^v_i && \text{for all } v\in\mathcal{V},i\in\Iv \label{eq:DLMMP:vehicle} \\
	& \alpha^* - \sum_{m\in\mathcal{M}}\sum_{t\in m}\hat{Y}_{m,i}\gamma^*_t \leq \hat{G}_i && \text{for all } i\in\Ihat \label{eq:DLMMP:route}
\end{align}

In order to find an optimal solution of $\eqref{eq:LMMP}$ we have to find indices $i\in\Iv$ or $j\in\Ihat$ where the previous constraints are violated. This leads to the following subproblems:

\begin{align*}
	& \text{Find } i\in\Iv\backslash\Jv \text{ s.t.} && \sum_{t\in\mathcal{T}}Y^v_{t,i}\gamma^*_t + \mu^*_v > G^v_i && \text{for } \vinV \\
	& \text{Find } i\in\Ihat\backslash\hat{\mathcal{J}} \text{ s.t.} && \alpha^*-\sum_{m\in\mathcal{M}}\sum_{t\in m}\hat{Y}_{m,i}\gamma^*_t > \hat{G}_i
\end{align*}

The vehicle subproblem $\eqref{eq:SPv}$ was already considered before. For the route choice, an additional subproblem arises.

\paragraph{Route Subproblem} \parfill

The route subproblem for finding violated constraints $\eqref{eq:DLMMP:route}$ reads as follows:

\begin{align*}
	\min \quad & \sum_{m\in\mathcal{M}}u_m\left(\croute_m + \sum_{t\in m}\gamma^*_t\right) \tag{$\SPm$} \label{SPm} \\
	\text{s.t.} \quad & \sum_{m\in C^{-1}(c)}u_m = 1 && \text{for all } c\in\mathcal{C} \\
	& u_m\in\{0,1\} && \text{for all } m\in\mathcal{M}
\end{align*}

This problem is easy to solve: For every $c\in\mathcal{C}$ choose the multimodal route $m\in C^{-1}(c)$ with the smallest cost $\croute_m + \sum_{t\in m}\gamma^*_t$. 

Let $\bar{u}$ be an optimal solution of $\eqref{SPm}$. If $\operatorname{val}\left(\bar{u}\right)<\alpha^*$ then add this to $\hat{\mathcal{J}}$ and continue the master problem.